# Проекты

## Открытые проекты

### VLMHyperBench

VLMHyperBench – open source фреймворк для оценки возможностей мультимодальных моделей распознавать документы на русском языке с целью оценки их потенциала для автоматизации документооборота.

#### Описание

Сейчас для обработки каждого нового документа со своей структурой разрабатываются специальные решения с использованием подходов Optical character recognition (OCR). Используя Vision language models (VLM) можно заменить разработку нового узкоспециализированого решения под новую структуру на подбор подходящего промпта для извлечения нужных данных из сканов документов. В настоящее время область мульти-модальных моделей интенсивно развивается: появляются новые модели, фреймворки для инференса моделей и востребованы инструменты, которые позволять производить объективное сравнение моделей по метрикам, потребляемым ресурсам и скорости инференса на наборах данных компании/исследователей.

Разрабатываемый фреймворк VLMHyperBench позволяет запускать каждую VLM в своем собственном изолированном в Docker-контейнере окружении. Это позволяет сравнивать между собой модели несовместимые по зависимостям, запускаемым на разных фреймворках инференса (Hugging Face, vLLM, SGLang), автоматизировать тестирование Docker-контейнеров с VLM моделями в CI/CD пайплайнах компаний.

Разрабатываемое ПО будет являться open source инструментом, рассчитанными как на инженеров ит компаний, так и на исследователей. Проект придерживается модульной архитектуры для легкого добавления своих наборов данных, контейнеров с VLM, метрик и визуализаций результатов оценки. В будущем планируем добавлять поддержку и оркестрацию пайплайнов с другими видами контейнеров (в ближайших планах Apptainer/Singularity).

#### Материалы по проекту

- [Презентация (слайды)](https://docs.google.com/presentation/d/1Aa9zYWa_FOGln1Z0OZ2sXzcPbFYCBfgJK-Xh4_mYlPU/edit#slide=id.p)
- [Презентация (текст)](https://docs.google.com/document/d/13jB_jlHbUwCNLsnJ60Z-qJY5eHM11sg3r7cIndnxlYk/edit?tab=t.0)
- [GitHub организации VLMHyperBenchTeam](https://github.com/orgs/VLMHyperBenchTeam/repositories)
- [Container registry с Docker-образами](https://github.com/orgs/VLMHyperBenchTeam/packages)
- [Сайт с документацией проекта](https://vlmhyperbenchteam.github.io/VLMHyperBenchDocs/)
  - [Главная страница](https://vlmhyperbenchteam.github.io/VLMHyperBenchDocs/)
  - [Документация API](https://vlmhyperbenchteam.github.io/VLMHyperBenchDocs/docs/category/api-docs)
  - [Блог](https://vlmhyperbenchteam.github.io/VLMHyperBenchDocs/blog)
- [Генератор документации для Python-пакетов](https://github.com/VLMHyperBenchTeam/python_api_docs)
- [Архитектура ПО VLMHyperBench в С4 диаграммах в Draw.io](https://drive.google.com/file/d/1o4nyLsC-T8OGUrBmCNb4Tvr0_LtFqp1p/view)

#### Грант

Грант «Альфа шанс» пойдет на развитие данного проекта: привлечение внимания к проекту через участие в ит конференциях и аренду облачных серверов с видеокартами для вычислений.

### EmotionRec

EmotionRec – open source проект по распознаванию эмоций человека для сервисов онлайн видео звонков, таких как Zoom, Skype и т.д.

#### Описание

В рамках проекта я собрал решение, которое использует State of art модель, показывающая лучший результат на датасете RAVDESS на данный момент времени – intermediate transformer fusion из статьи Self-attention fusion for audiovisual emotion recognition with incomplete data.

#### Ссылки

- [Репозиторий проекта](https://gitlab.com/group_19200719)
- [State of art модель](https://paperswithcode.com/sota/facial-emotion-recognition-on-ravdess)
- [Датасет RAVDESS](https://zenodo.org/record/1188976#.YFZuJ0j7SL8)
- [Статья Self-attention fusion for audiovisual emotion recognition with incomplete data](https://arxiv.org/abs/2201.11095)

#### Особенности

Все решения, представленные в репозитории, упакованы в отдельные python-пакеты, которые легко и удобно использовать (например, python-пакет «pytorch_retinaface_infer»). Я придерживался модульной структуры, чтобы мои разработки было удобно использовать всем желающим в своих проектах независимо от моего.

#### Курсы

Проект подготовлен при прохождении онлайн-курсов на платформе Open Data Science:

- **My First Data Project 2: от идеи к продукту** – [ссылка](https://ods.ai/tracks/mfdp2)
  - Итогом данного курса стало поступление в онлайн магистратуру ИТМО "Искусственный интеллект" от AI Talent Hub на бюджет – [ссылка](https://ai.itmo.ru/)

- **MLOps и production подход к ML исследованиям 2.0** – [ссылка](https://ods.ai/tracks/ml-in-production-spring-23)
  - [Видео записи защиты проекта](https://www.youtube.com/live/8ceKOYlQ6MA?si=N1ONjUZ5n6cHPkpM&t=2848)
  - По итогу данного курса я занял 1-ое место в общем лидерборде – [ссылка](https://ods.ai/tracks/ml-in-production-spring-23/leaderboard)

### Driver'sHelper

Driver'sHelper – pet-проект прототипа помощника для водителей, который будет оповещать их о дорожных знаках.

#### Описание

Проект посвящен разработке системы компьютерного зрения для «умного видео регистратора». Данный видео регистратор распознает дорожные знаки в режиме реального времени и оповещает водителя о них.

#### Ссылки

- [Репозиторий проекта](https://github.com/medphisiker/drivers_helper)
- [YouTube-плейлист с демо видео](https://www.youtube.com/playlist?list=PL71idmSpGAF2KZyzZCrsFtyJgqmPQf2od)

#### Особенности

В рамках проекта подготовлено 3 модели. По приблизительным оценкам данные модели способны работать на ЦПУ современных смартфонов в режиме реального времени от 18 до 52 FPS.

### CareerRank

CareerRank – pet-проект прототипа сервиса для подбора подходящих друг другу вакансий и резюме.

#### Описание

Проект использует нейросетевые языковые модели (LM) для подбора подходящих друг другу вакансий и резюме на основе их текстовых описаний.

#### Ссылки

- [Репозиторий проекта](https://github.com/medphisiker/maching_cv_and_vacancy)
- [Видео демо работы сервиса](https://youtu.be/ThIdllGH9ug?si=qv5YGrYYDQkxls67&t=34)

#### Особенности

Сервис использует модель, работающую с русским и английским языком. Это актуально для ит-вакансий и резюме, когда текст описания может быть на русском языке, но содержать термины из ит области на английском языке, например DevOps, Data Scientist и т.д.

## Непубличные проекты

Их код находится в корпоративных репозиториях. Могу рассказать про них и привести ссылки на демонстрацию их работы.

### Система компьютерного зрения для подводного робота

#### Описание

Проект по разработке системы компьютерного зрения для телеуправляемого необитаемого подводного аппарата (ТНПА) для обнаружения представителей морской фауны в интересах мониторинга марикультуры.

#### Стек технологий

- Платформа: nVidia Jetson ARM64
- Языки: Python
- Фреймворки: PyTorch, Jetson-Inference

#### Материалы

В результате на ВЭФ 2022 года был представлен наш аппарат:

- [Демо детектора](https://youtu.be/pVVztrvrCGw?si=9IjjOQp7v_v0uVUL)
- [Ссылка о ТНПА](https://primamedia.ru/news/1355123/)
- [Сюжет на Первом канале (с 7:20)](https://www.1tv.ru/news/2022-09-05/437156-vypusk_novostey_v_14_00_ot_05_09_2022)

### Система компьютерного зрения для автоматизации конвейерной сортировки рыбоперерабатывающего завода

#### Описание

Проект по разработке системы компьютерного зрения для автоматизации конвейерной сортировки рыбоперерабатывающего завода с помощью системы компьютерного зрения и дельта-робота: сегментация и SORT-треккинг.

#### Стек технологий

- Платформа: AMD64 с Nvidia GPU Linux Ubuntu Server
- Языки: Python
- Фреймворки: PyTorch, MMDetection, Detectron2, onnx, onnxruntime, TensorRT

#### Материалы

- [Демо скученная рыба Masked RCNN](https://youtu.be/WCiPduGcIO8?si=vj-Ah93mLjLdZH1t&t=6)
- [Демо системы компьютерного зрения и сортировки рыбы](https://youtu.be/dGKP4fjohhM?si=BcBhdOgE-v9JleW9)

#### Особенности

Для этой задачи я размечал данные в CVAT, используя f-BRS, HRNet. Сейчас я так же использую интеграцию Segment Anything (SAM) от Facebook в CVAT. Она существенно ускоряет процесс разметки – [ссылка](https://youtu.be/99VzS8CqqX0?si=UXGLPT2o0HIUvlzG&t=200).

Я так же автоматизировал процесс сбора видео с конвейера на рыбозаводе. На небольшом сервере на ЦПУ запущен docker-контейнер с YOLOv8. Каждые 2.5 минуты python-скрипт получает кадр с ip-камеры, расположенной над конвейером. Данный кадр отдается нейросети, если она обнаруживает в кадре рыбу включается запись видео на 10 минут. Далее цикл повторяется.

### Проект по распознаванию действий людей на видео

#### Описание

В рамках стажировки в магистратуре ИТМО я проходил стажировку в компании стартапе Linza Metrics. Решение от Linza Metrics состоит в анализе перемещений и действий участников процессов с помощью видеонаблюдения, поиске статистических закономерностей, разработке рекомендаций, повышающих эффективность бизнес-процессов. Бизнес-ценность состоит в повышении эффективности рабочих процессов.

Задача компьютерного зрения – абстрактное пространственно-временное обнаружение действий (STAD) сводится к обнаружению интервала времени (клипа), в котором один человек делает один вид действия.

#### Решение

Я произвел обзор существующих подходов и моделей и предложил модель YOWOv2 (2023г). Написал для нее обучение на Lightning, обернул в удобный инференс класс, написал визуализацию предсказаний от модели.

#### Результаты

В результате удалось получить модель с производительностью в реальном времени 16-18 FPS на ЦПУ (100 FPS на ГПУ) и метрикой F-mAP ~0.8 на датасете UCF24 Sports.

Тестирование произведено на:
- GPU nVidia A10
- ЦПУ 12th Gen Intel(R) Core(TM) i5-12600

Ментор компании ставил задачу на 2-3 FPS на ЦПУ.

#### Демонстрации

- [Распознавание действий на выступлении Камиллы Валиевой](https://youtu.be/AjWqWaQlvto)
- [Репетиция команды по синхронному фигурному катанию Sunrise](https://youtu.be/6z_w_qQbGMk)
- [Визуализация на девушке, осуществляющей верховую езду](https://youtu.be/c2cYAWntZgk?si=KSdVU7Kb93TG2dZe)

Интересно, что, анализируя выступление Камиллы, модель часто присваивает ее действиям еще и второй класс – Floor Gymnastics. Я с ней согласен =)
